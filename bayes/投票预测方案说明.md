# 从淘汰顺序反推投票数量的方案

## 问题描述

根据Plackett-Luce模型和淘汰顺序，反推每位选手的投票数量。投票数量是未知的，需要从淘汰顺序推断。

## 方案概述

提供了**4种方法**来预测投票数量：

### 方法1: 贝叶斯方法（推荐用于不确定性估计）

**原理：**
- 将投票数量作为隐变量，使用贝叶斯推断
- 假设投票数服从对数正态分布的先验
- 使用最大后验估计（MAP）和MCMC采样估计不确定性

**优点：**
- 提供不确定性估计（置信区间）
- 理论基础扎实
- 可以量化预测的可靠性

**缺点：**
- 计算较慢
- 需要设置先验参数

**代码：**
```python
result = vp.bayesian_vote_prediction(X, elimination_order, 
                                     prior_mean=1000, prior_std=500)
votes = result['votes_map']  # 最大后验估计
votes_std = result['votes_std']  # 不确定性
```

### 方法2: 最大似然估计（MLE）

**原理：**
- 直接优化投票数量，使Plackett-Luce模型的似然最大
- 不假设先验分布

**优点：**
- 计算快速
- 不需要先验假设
- 简单直接

**缺点：**
- 不提供不确定性估计
- 可能陷入局部最优

**代码：**
```python
result = vp.mle_vote_prediction(elimination_order)
votes = result['votes']
```

### 方法3: 两阶段方法（推荐，平衡准确性和效率）

**原理：**
1. **阶段1**：使用Plackett-Luce模型估计实力分数mu
2. **阶段2**：将mu映射到投票数量（假设 votes = a * exp(mu) + b）

**优点：**
- 结合了特征信息和淘汰顺序
- 计算效率高
- 可以估计不确定性
- **推荐使用此方法**

**缺点：**
- 需要假设mu和投票数的关系

**代码：**
```python
result = vp.two_stage_vote_prediction(X, elimination_order, 
                                      mu_from_features=mu)
votes = result['votes']
votes_std = result['votes_std']
```

### 方法4: 基于特征的回归方法

**原理：**
- 使用已训练的模型得到的mu（从特征预测）
- 然后回归到投票数量

**优点：**
- 充分利用特征信息
- 可以处理新选手（有特征但无历史数据）

**缺点：**
- 需要先训练特征模型
- 依赖特征质量

**代码：**
```python
# 先训练模型得到mu
mu = compute_mu(X, w_trained)

# 然后预测投票数
result = vp.regression_vote_prediction(X, elimination_order, mu)
votes = result['votes']
```

## 使用建议

### 场景1: 需要不确定性估计
→ 使用 **方法1（贝叶斯方法）**

### 场景2: 快速预测，不需要不确定性
→ 使用 **方法2（MLE）**

### 场景3: 平衡准确性和效率（推荐）
→ 使用 **方法3（两阶段方法）**

### 场景4: 有特征模型，想利用特征信息
→ 使用 **方法4（回归方法）**

## 完整使用示例

```python
import vote_prediction as vp
import numpy as np

# 准备数据
X = ...  # 特征矩阵
elimination_order = [2, 0, 1]  # 淘汰顺序
mu_from_model = ...  # 从特征模型得到的mu（可选）

# 方法1: 贝叶斯方法
result_bayesian = vp.bayesian_vote_prediction(X, elimination_order)
print("贝叶斯预测:", result_bayesian['votes_map'])
print("不确定性:", result_bayesian['votes_std'])

# 方法2: MLE
result_mle = vp.mle_vote_prediction(elimination_order)
print("MLE预测:", result_mle['votes'])

# 方法3: 两阶段方法（推荐）
result_two_stage = vp.two_stage_vote_prediction(X, elimination_order, mu_from_model)
print("两阶段预测:", result_two_stage['votes'])

# 方法4: 综合预测（使用所有方法）
results_all = vp.predict_votes_comprehensive(X, elimination_order, 
                                            mu_from_model=mu_from_model, 
                                            method='all')
```

## 集成使用

使用 `integrated_vote_prediction.py` 可以：
1. 自动加载数据
2. 对每个季节训练模型
3. 预测投票数量
4. 保存结果到CSV

```bash
python integrated_vote_prediction.py
```

## 评估指标

每个方法都会计算：
- **淘汰顺序一致性**（Kendall's tau）：预测的投票数产生的淘汰顺序与实际的一致性
- **不确定性估计**：预测的可靠性（仅贝叶斯和两阶段方法）

## 数学原理

### Plackett-Luce模型

在Plackett-Luce模型中，选手i被淘汰的概率为：

$$P(\text{淘汰} i | \text{存活集合} S) = \frac{e^{-\mu_i}}{\sum_{j \in S} e^{-\mu_j}}$$

其中 $\mu_i$ 是选手i的实力分数。

### 投票数量与mu的关系

假设投票数量与实力分数相关：
- **线性关系**：$v_i = a \cdot e^{\mu_i} + b$
- **对数关系**：$\mu_i = \log(v_i + \epsilon)$

### 贝叶斯推断

后验分布：
$$P(v | \text{淘汰顺序}) \propto P(\text{淘汰顺序} | v) \cdot P(v)$$

其中：
- 似然项：Plackett-Luce模型的概率
- 先验项：投票数的先验分布（对数正态分布）

## 注意事项

1. **投票数量必须为正**：所有方法都确保预测的投票数 > 0
2. **相对大小更重要**：投票数的绝对大小可能不准确，但相对大小（排名）应该准确
3. **不确定性**：预测的投票数有不确定性，特别是当数据量少时
4. **特征质量**：如果使用特征，特征的质量直接影响预测准确性

## 文件说明

- `vote_prediction.py`: 核心预测函数
- `integrated_vote_prediction.py`: 集成脚本，自动处理所有季节
- `投票预测方案说明.md`: 本文档

